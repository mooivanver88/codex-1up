# ~/.codex/config.toml (created by codex-1up if missing)
# Adjust to your liking. See Codex CLI docs for full options.

# Core
model = "gpt-5"
approval_policy = "on-request"       # untrusted|on-failure|on-request|never
sandbox_mode   = "workspace-write"   # read-only|workspace-write|danger-full-access

[tools] 
web_search = true

# Optional privacy & UX
# disable_response_storage = true     # zero-data-retention mode
# file_opener = "vscode"              # vscode|vscode-insiders|windsurf|cursor|none

# Reasoning / verbosity (GPTâ€‘5 family)
# model_reasoning_effort = "medium"   # minimal|low|medium|high|none
# model_verbosity = "medium"          # low|medium|high
# model_reasoning_summary = "auto"    # auto|concise|detailed|none

# Sandbox network: keep off unless you need arbitrary HTTP (curl, etc.)
# [sandbox_workspace_write]
# network_access = false

# Example: MCP server
# [mcp_servers.server-name]
# command = "npx"
# args = ["-y", "mcp-remote", "https://example.com/api/mcp"]

# Example: Azure provider profile
# [profiles.azure]
# model = "gpt-5"
# model_provider = "azure"
# [model_providers.azure]
# name = "Azure"
# base_url = "https://<resource>.openai.azure.com/openai"
# env_key = "AZURE_OPENAI_API_KEY"
# query_params = { api-version = "2025-04-01-preview" }
# wire_api = "responses"